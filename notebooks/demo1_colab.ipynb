{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5201e56a",
   "metadata": {},
   "source": [
    "# Demo 1 – Minecraft Sound Generation with AudioLDM2\n",
    "\n",
    "**Goal:** Show that small-scale LoRA adaptation of AudioLDM2 shifts generations toward Minecraft SFX.\n",
    "\n",
    "**Runtime:** Google Colab with T4 GPU\n",
    "\n",
    "### Pipeline\n",
    "1. Clone repo & install dependencies\n",
    "2. Fetch Minecraft sound assets (zombie & skeleton categories)\n",
    "3. Preprocess audio → 16 kHz mono .wav, fixed 4 s length\n",
    "4. Build manifest (metadata.csv with captions + train/val split)\n",
    "5. Generate **baseline** samples from vanilla AudioLDM2\n",
    "6. LoRA fine-tune UNet on the Minecraft dataset\n",
    "7. Generate **adapted** samples and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76beca7",
   "metadata": {},
   "source": [
    "---\n",
    "## 0 · Check GPU & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9db321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU is available\n",
    "!nvidia-smi --query-gpu=name,memory.total --format=csv,noheader\n",
    "\n",
    "import torch\n",
    "print(f\"PyTorch {torch.__version__}  |  CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45aff150",
   "metadata": {},
   "source": [
    "---\n",
    "## 1 · Clone Repo & Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcec430",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ── Clone the project repo (change URL to your fork) ──\n",
    "REPO_URL = \"https://github.com/<YOUR_USERNAME>/GenAI-Minecraft-Sounds.git\"  # TODO: update\n",
    "REPO_DIR = \"/content/GenAI-Minecraft-Sounds\"\n",
    "\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    !git clone {REPO_URL} {REPO_DIR}\n",
    "os.chdir(REPO_DIR)\n",
    "print(f\"Working directory: {os.getcwd()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5e4ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Install Python dependencies ──\n",
    "# Pin transformers & diffusers to versions compatible with AudioLDM2\n",
    "!pip install -q librosa soundfile pydub pyyaml requests tqdm\n",
    "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install -q \"diffusers[torch]>=0.27,<=0.32.2\" \"transformers>=4.36,<=4.44.2\" accelerate peft datasets scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffb1d7b",
   "metadata": {},
   "source": [
    "---\n",
    "## 2 · Fetch Minecraft Sound Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e49709",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/fetch_minecraft_assets.py --config configs/demo1.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ada14e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: list downloaded files\n",
    "import glob\n",
    "\n",
    "ogg_files = sorted(glob.glob(\"data/raw/**/*.ogg\", recursive=True))\n",
    "print(f\"Total .ogg files downloaded: {len(ogg_files)}\")\n",
    "for f in ogg_files[:10]:\n",
    "    print(f\"  {f}\")\n",
    "if len(ogg_files) > 10:\n",
    "    print(f\"  ... and {len(ogg_files) - 10} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b2447",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 · Preprocess Audio\n",
    "\n",
    "Convert .ogg → .wav at 16 kHz, mono, trimmed silence, padded/clipped to 4 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e3604cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/preprocess_audio.py --config configs/demo1.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83267a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: verify processed files\n",
    "import soundfile as sf\n",
    "import numpy as np\n",
    "\n",
    "wav_files = sorted(glob.glob(\"data/processed/**/*.wav\", recursive=True))\n",
    "print(f\"Total processed .wav files: {len(wav_files)}\")\n",
    "\n",
    "# Spot-check first 3 files\n",
    "for wf in wav_files[:3]:\n",
    "    audio, sr = sf.read(wf, dtype=\"float32\")\n",
    "    dur = len(audio) / sr\n",
    "    print(f\"  {wf}  |  sr={sr}  dur={dur:.2f}s  \"\n",
    "          f\"range=[{audio.min():.3f}, {audio.max():.3f}]  \"\n",
    "          f\"shape={audio.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515a8ed3",
   "metadata": {},
   "source": [
    "---\n",
    "## 4 · Build Manifest (metadata.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d0b79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python scripts/build_manifest.py --config configs/demo1.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef96abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the manifest\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/manifest.csv\")\n",
    "print(f\"Manifest shape: {df.shape}\")\n",
    "print(f\"Split counts:\\n{df['split'].value_counts()}\")\n",
    "print()\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c2dbbb",
   "metadata": {},
   "source": [
    "---\n",
    "## 5 · Listen to a Few Samples\n",
    "\n",
    "Play some processed Minecraft sounds to verify quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d419be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "\n",
    "for wf in wav_files[:4]:\n",
    "    print(f\"\\n▶ {wf}\")\n",
    "    audio, sr = sf.read(wf, dtype=\"float32\")\n",
    "    display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29f0484f",
   "metadata": {},
   "source": [
    "---\n",
    "## 6 · Baseline Generation (Vanilla AudioLDM2)\n",
    "\n",
    "Generate samples from the pre-trained model *before* any fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929f1744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate baseline samples for a couple of prompts\n",
    "PROMPTS = [\n",
    "    \"minecraft zombie hurt sound effect\",\n",
    "    \"minecraft skeleton death sound effect\",\n",
    "]\n",
    "\n",
    "for prompt in PROMPTS:\n",
    "    !python -m src.mcaudio.infer.generate \\\n",
    "        --prompt \"{prompt}\" \\\n",
    "        --config configs/demo1.yaml \\\n",
    "        --num_samples 4 \\\n",
    "        --output outputs/demo1/baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e1d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to baseline generations\n",
    "baseline_wavs = sorted(glob.glob(\"outputs/demo1/baseline/*.wav\"))\n",
    "print(f\"Baseline samples: {len(baseline_wavs)}\")\n",
    "\n",
    "for wf in baseline_wavs[:4]:\n",
    "    print(f\"\\n▶ {os.path.basename(wf)}\")\n",
    "    audio, sr = sf.read(wf, dtype=\"float32\")\n",
    "    display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccf2096e",
   "metadata": {},
   "source": [
    "---\n",
    "## 7 · LoRA Fine-Tuning  *(optional for Demo 1)*\n",
    "\n",
    "Fine-tune the UNet with LoRA adapters on the Minecraft dataset.\n",
    "\n",
    "> **Note:** This takes ~15-30 min on T4. You can reduce `max_train_steps` for a quicker test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c32a6c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to run training:\n",
    "# !python -m src.mcaudio.train.lora_train --config configs/demo1.yaml --max_steps 200"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c4e26",
   "metadata": {},
   "source": [
    "---\n",
    "## 8 · Generate with LoRA Adapter  *(after training)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48012712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment after LoRA training completes:\n",
    "# for prompt in PROMPTS:\n",
    "#     !python -m src.mcaudio.infer.generate \\\n",
    "#         --prompt \"{prompt}\" \\\n",
    "#         --config configs/demo1.yaml \\\n",
    "#         --lora_weights outputs/demo1/lora_weights \\\n",
    "#         --num_samples 4 \\\n",
    "#         --output outputs/demo1/lora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0270eed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Listen to LoRA-adapted generations\n",
    "# lora_wavs = sorted(glob.glob(\"outputs/demo1/lora/*.wav\"))\n",
    "# print(f\"LoRA samples: {len(lora_wavs)}\")\n",
    "#\n",
    "# for wf in lora_wavs[:4]:\n",
    "#     print(f\"\\n▶ {os.path.basename(wf)}\")\n",
    "#     audio, sr = sf.read(wf, dtype=\"float32\")\n",
    "#     display(ipd.Audio(audio, rate=sr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9cb783b",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "| Stage | Artefact | Location |\n",
    "|-------|----------|----------|\n",
    "| Raw assets | .ogg files | `data/raw/` |\n",
    "| Processed | 16 kHz mono .wav | `data/processed/` |\n",
    "| Manifest | metadata.csv | `data/manifest.csv` |\n",
    "| Baseline | generated .wav | `outputs/demo1/baseline/` |\n",
    "| LoRA weights | adapter checkpoint | `outputs/demo1/lora_weights/` |\n",
    "| LoRA samples | generated .wav | `outputs/demo1/lora/` |"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
